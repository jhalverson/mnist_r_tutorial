# mnist_r_tutorial
Using a GPU node for deep learning with R and Keras
